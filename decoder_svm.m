function [trainedClassifier, validationAccuracy] = decoder_svm(trainingData, responseData, do_pca)
% [trainedClassifier, validationAccuracy] = trainClassifier(trainingData,
% responseData)
% Returns a trained classifier and its accuracy. This code recreates the
% classification model trained in Classification Learner app. Use the
% generated code to automate training the same model with new data, or to
% learn how to programmatically train models.
%
%  Input:
%      trainingData: A matrix with the same number of columns and data type
%       as the matrix imported into the app.
%
%      responseData: A vector with the same data type as the vector
%       imported into the app. The length of responseData and the number of
%       rows of trainingData must be equal.
%
%
%  Output:
%      trainedClassifier: A struct containing the trained classifier. The
%       struct contains various fields with information about the trained
%       classifier.
%
%      trainedClassifier.predictFcn: A function to make predictions on new
%       data.
%
%      validationAccuracy: A double representing the validation accuracy as
%       a percentage. In the app, the Models pane displays the validation
%       accuracy for each model.
%
% Use the code to train the model with new data. To retrain your
% classifier, call the function from the command line with your original
% data or new data as the input arguments trainingData and responseData.
%
% For example, to retrain a classifier trained with the original data set T
% and response Y, enter:
%   [trainedClassifier, validationAccuracy] = trainClassifier(T, Y)
%
% To make predictions with the returned 'trainedClassifier' on new data T2,
% use
%   [yfit,scores] = trainedClassifier.predictFcn(T2)
%
% T2 must be a matrix containing only the predictor columns used for
% training. For details, enter:
%   trainedClassifier.HowToPredict

% Auto-generated by MATLAB on 22-Nov-2023 13:15:16


% Extract predictors and response
% This code processes the data into the right shape for training the
% model.
% Convert input to table

inputTable = array2table(trainingData);

predictorNames = inputTable.Properties.VariableNames;

classNames = unique(responseData);

[num_tr, num_cells] = size(trainingData);

response = responseData;

if do_pca
    % Apply a PCA to the predictor matrix.
    numericPredictors = trainingData;
    % 'inf' values have to be treated as missing data for PCA.
    numericPredictors(isinf(numericPredictors)) = NaN;
    [pcaCoefficients, pcaScores, ~, ~, explained, pcaCenters] = pca(numericPredictors);

    % Keep enough components to explain the desired amount of variance.
    explainedVarianceToKeepAsFraction = 95/100;
    numComponentsToKeep = find(cumsum(explained)/sum(explained) >= explainedVarianceToKeepAsFraction, 1);
    
    pcaCoefficients = pcaCoefficients(:,1:numComponentsToKeep);
    
    predictors = array2table(pcaScores(:,1:numComponentsToKeep));
else
    predictors = inputTable(:, predictorNames);
end

% Train a classifier
% This code specifies all the classifier options and trains the classifier.
template = templateSVM(...
    'KernelFunction', 'linear', ...
    'PolynomialOrder', [], ...
    'KernelScale', 'auto', ...
    'BoxConstraint', 1, ...
    'Standardize', true);
classificationSVM = fitcecoc(...
    predictors, ...
    responseData, ...
    'Learners', template, ...
    'Coding', 'onevsall', ...
    'ClassNames', classNames);

% Create the result struct with predict function
predictorExtractionFcn = @(x) array2table(x, 'VariableNames', predictorNames);
svmPredictFcn = @(x) predict(classificationSVM, x);
if do_pca
    pcaTransformationFcn = @(x) array2table((table2array(x) - pcaCenters) * pcaCoefficients);
    trainedClassifier.predictFcn = @(x) svmPredictFcn(pcaTransformationFcn(predictorExtractionFcn(x)));
    trainedClassifier.PCACenters = pcaCenters;
    trainedClassifier.PCACoefficients = pcaCoefficients;
else
    trainedClassifier.predictFcn = @(x) svmPredictFcn(predictorExtractionFcn(x));
end

% Add additional fields to the result struct
trainedClassifier.ClassificationSVM = classificationSVM;
trainedClassifier.About = 'This struct is a trained model exported from Classification Learner R2023a.';
trainedClassifier.HowToPredict = sprintf('To make predictions on a new predictor column matrix, X, use: \n  [yfit,scores] = c.predictFcn(X) \nreplacing ''c'' with the name of the variable that is this struct, e.g. ''trainedModel''. \n \nX must contain exactly 86 columns because this model was trained using 86 predictors. \nX must contain only predictor columns in exactly the same order and format as your training \ndata. Do not include the response column or any columns you did not import into the app. \n \nFor more information, see <a href="matlab:helpview(fullfile(docroot, ''stats'', ''stats.map''), ''appclassification_exportmodeltoworkspace'')">How to predict using an exported model</a>.');

% Extract predictors and response
% This code processes the data into the right shape for training the
% model.
% Convert input to table

% Perform cross-validation
KFolds = 5;
cvp = cvpartition(response, 'KFold', KFolds);
% Initialize the predictions to the proper sizes
validationPredictions = response;
numObservations = size(predictors, 1);
numClasses = 10;
validationScores = NaN(numObservations, numClasses);
for fold = 1:KFolds
    trainingPredictors = predictors(cvp.training(fold), :);
    trainingResponse = response(cvp.training(fold), :);

    % Apply a PCA to the predictor matrix.
    % Run PCA on numeric predictors only. Categorical predictors are passed through PCA untouched.

    % Keep enough components to explain the desired amount of variance.
    if do_pca
        numericPredictors = trainingPredictors;
        numericPredictors = table2array(numericPredictors);
        % 'inf' values have to be treated as missing data for PCA.
        numericPredictors(isinf(numericPredictors)) = NaN;
        [pcaCoefficients, pcaScores, ~, ~, explained, pcaCenters] = pca(numericPredictors);

        numComponentsToKeep = find(cumsum(explained)/sum(explained) >= explainedVarianceToKeepAsFraction, 1);
        pcaCoefficients = pcaCoefficients(:,1:numComponentsToKeep);
        trainingPredictors = array2table(pcaScores(:,1:numComponentsToKeep));
    end

    % Train a classifier
    % This code specifies all the classifier options and trains the classifier.
    template = templateSVM(...
        'KernelFunction', 'linear', ...
        'PolynomialOrder', [], ...
        'KernelScale', 'auto', ...
        'BoxConstraint', 1, ...
        'Standardize', true);
    classificationSVM = fitcecoc(...
        trainingPredictors, ...
        trainingResponse, ...
        'Learners', template, ...
        'Coding', 'onevsall', ...
        'ClassNames', classNames);

    % Create the result struct with predict function
    svmPredictFcn = @(x) predict(classificationSVM, x);
    if do_pca
        pcaTransformationFcn = @(x) array2table((table2array(varfun(@double, x)) - pcaCenters) * pcaCoefficients);
        validationPredictFcn = @(x) svmPredictFcn(pcaTransformationFcn(x));
    else
        validationPredictFcn = @(x) svmPredictFcn(x);
    end
    
    % Add additional fields to the result struct

    % Compute validation predictions
    validationPredictors = predictors(cvp.test(fold), :);
    [foldPredictions, foldScores] = validationPredictFcn(validationPredictors);

    % Store predictions in the original order
    validationPredictions(cvp.test(fold), :) = foldPredictions;
    validationScores(cvp.test(fold), :) = foldScores;
end

% Compute validation accuracy
correctPredictions = (validationPredictions == response);
isMissing = isnan(response);
correctPredictions = correctPredictions(~isMissing);
validationAccuracy = sum(correctPredictions)/length(correctPredictions);
